{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantxt(fname):\n",
    "    rawname = fname+'_raw'\n",
    "    if fname[-3:]=='txt':\n",
    "        rawname = fname[:-4]+'_raw.txt'\n",
    "    \n",
    "    with open(fname, 'r') as f, open(rawname, 'a') as rawf:\n",
    "        content = f.readlines()\n",
    "        for line in f:\n",
    "            rawf.write(line)\n",
    "            \n",
    "    # remove whitespace at the end. keep the tab \\t to mark level of question    \n",
    "    content = [x.strip('\\n') for x in content] \n",
    "   \n",
    "    for line in content:\n",
    "        if line[0]==' ': # transform white spaces into tab which is used to count levels\n",
    "            line = line.replace('  ','\\t') \n",
    "        if line.find('？')>0: # deal with chinese characters\n",
    "            line = line.replace('？','?')\n",
    "        if line.find('。')>0:\n",
    "            line = line.replace('。','.')\n",
    "        with open(fname, 'w') as wf: # rewrite the original text name so nothing weird in the processed textfile.\n",
    "            wf.write(line+'\\n')\n",
    "    return content,cleanname\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to quesnet\n",
    "For paper notes, the first line will be the title of this paper, which should be linked to the paper data structure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getedge(head):\n",
    "    # get edge\n",
    "    if head.find('...')>0 and head.find('_')>0: # edge of a group head\n",
    "        ed = head[head.find('_')+1:head.find('...')]\n",
    "    else: # edge of single node\n",
    "        ed = head[head.find('_')+1:head.rfind('_')]\n",
    "    #unify the edge label names\n",
    "    if ed == 'a' or ed.lower()=='answer':\n",
    "        ed = 'answer' # rename the txt shorthand\n",
    "    elif ed == 'specify':\n",
    "        ed = 'specification'\n",
    "    # get speaker\n",
    "    if head.find('@')>0: # speaker other than this paper -- usually me\n",
    "        speaker = head[head.find('@')+1:]\n",
    "    else:\n",
    "        speaker = ''\n",
    "    return ed,speaker\n",
    "def node2label(node):\n",
    "    if node.find('\"')>0:\n",
    "        label = node[:node.find('\"')]\n",
    "        content = node[node.find('\"'):]\n",
    "    else:\n",
    "        label = node\n",
    "        content=\"\"\n",
    "    return label,content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2quesnet(outdir,combrepQ = True,fin='',nodedist={},alledge=[]):\n",
    "    for key in ['label','type','id','content','speaker','level']:\n",
    "        nodedist[key]=[]\n",
    "    with open(fin,'r') as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    # create a paper entity\n",
    "    thisp = {'id':'Ep%d'%np.random.randint(100000)} #E=entity,p=paper\n",
    "    #FUTURE: may use other ways to record the paper info\n",
    "    fname = fin[fin.rfind('/')+1:] # get rid of the file directory \n",
    "    print(fname)\n",
    "    thisp['label']=fname.strip('.txt')\n",
    "    for ks,s in enumerate(fname):\n",
    "        if s.isdigit():\n",
    "            thisp['author'] = fname[:ks]\n",
    "            break\n",
    "    thisp['year']=fname[ks:ks+4]\n",
    "    # if the first line is the paper name\n",
    "    lstart=0 # which line to start reading\n",
    "    if content[0]=='#':\n",
    "        thisp['title']=content[0][3:]\n",
    "        lstart=1\n",
    "        \n",
    "    # create multiple question threads from each root\n",
    "    maxlevel = 20 # maximum 20 levels down the tree\n",
    "    allngrps=[]\n",
    "    for line in content[lstart:]:\n",
    "        if len(line.strip())<1: # skip empty lines\n",
    "            continue\n",
    "        elif line[:2]=='##':#ending sign\n",
    "            break\n",
    "        else: # a valid new line\n",
    "            line = line.rstrip()\n",
    "            # new...\n",
    "            if line[0].isalpha(): # a root node doesn't start with tab\n",
    "                    rootlv=0\n",
    "                    rootlist = [[] for k in range(maxlevel)]# restart a new root list\n",
    "                    node = line\n",
    "                    edge = ''\n",
    "                    spkr = ''\n",
    "                    head = ''\n",
    "            else:\n",
    "                head = line.split(' ')[0]\n",
    "                if len(line.split(' '))==1:\n",
    "                    if line[-3:]=='...': #group head\n",
    "                        nodegrp = [] # for reading parallel nodes\n",
    "                        hdedge,hdspkr = getedge(head)                    \n",
    "                        continue\n",
    "                    elif line.find('end_')>0:\n",
    "                        allngrps.append(nodegrp)\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(line)\n",
    "                        print(\"can't recognize your grammar...\")  \n",
    "                        continue\n",
    "                else:\n",
    "                    node = \" \".join(line.split(' ')[1:])\n",
    "                    if head.find('...')<0: # a normal edge; otherwise a member of edge group, edge is given\n",
    "                        edge,spkr = getedge(head)\n",
    "                    else:\n",
    "                        edge,spkr = hdedge,hdspkr\n",
    "        # Construct the node dictionary, get nid   \n",
    "        level = int((len(line) - len(line.strip('\\t')))/len('\\t')) # an absolute level\n",
    "        label,content=node2label(node)\n",
    "        \n",
    "        if combrepQ and label in nodedist['label']:\n",
    "            nid = nodedist['id'][nodedist['label'].index(label)]\n",
    "        else:\n",
    "            if edge == 'answer' or edge =='hypothesis':\n",
    "                nodedist['type'].append('Answer') \n",
    "                nid = 'a%d'%np.random.randint(100000)\n",
    "            else:\n",
    "                nid = 'q%d'%np.random.randint(100000)\n",
    "                if level>0:\n",
    "                    nodedist['type'].append('Question')    \n",
    "                else:\n",
    "                    nodedist['type'].append('Root question')\n",
    "            nodedist['label'].append(label)\n",
    "            nodedist['id'].append(nid)\n",
    "            nodedist['content'].append(content)\n",
    "            nodedist['level'].append(level)\n",
    "            #nodedist['reference'].append(reference)\n",
    "            if len(spkr)==0:\n",
    "                spkr = thisp['id'] # if not specified, default speaker is this paper\n",
    "            nodedist['speaker'].append(spkr)\n",
    "        \n",
    "        if head.find('...')>0:\n",
    "            nodegrp.append(nid)       \n",
    "\n",
    "        \n",
    "        # Construct the edge dictionary    \n",
    "        rootlist[level]=nid             \n",
    "        if level>0:\n",
    "            if len(rootlist[level-1])==0:\n",
    "                print(node)\n",
    "                set_trace()\n",
    "            edgedict = {'start':rootlist[level-1],'end':nid,'label':edge,'id':'l%d'%np.random.randint(100000)}\n",
    "            if rootlist[level-1] == nid:\n",
    "                print(level)\n",
    "                print(line)\n",
    "                set_trace()\n",
    "            alledge.append(edgedict)   \n",
    "\n",
    "            \n",
    "    nodedf = pd.DataFrame(nodedist)\n",
    "    edgedf = pd.DataFrame(alledge) \n",
    "    #os.makedirs(filedir)\n",
    " \n",
    "    pickle.dump([nodedf,edgedf,allngrps],open(outdir+thisp['label']+'_qnet.p','bw'))\n",
    "    print('generated database in:\\n'+outdir+thisp['label']+'_qnet.p')\n",
    "    return thisp # output the paper entity. TODO: other entities mentioned in the nodes should also be added, so that return a full database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"fname='../txtnotes/papernotes/Dezza2017_Learning'\\noutdir='../database/curiosity/compcogsci/'\\nEpaper=txt2quesnet(outdir,False,fname) \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"fname='../txtnotes/papernotes/Dezza2017_Learning'\n",
    "outdir='../database/curiosity/compcogsci/'\n",
    "Epaper=txt2quesnet(outdir,False,fname) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodeQs.txt\n",
      "generated database in:\n",
      "../database/curiosity/devpsych/nodeQs_qnet.p\n"
     ]
    }
   ],
   "source": [
    "fname='../database/curiosity/devpsych/nodeQs.txt'\n",
    "outdir='../database/curiosity/devpsych/'\n",
    "Epaper=txt2quesnet(outdir,False,fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../database/curiosity/compcogsci//nodeQs.txt_qnet.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d2b15746031f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mnodedf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgedf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallngrps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../database/curiosity/compcogsci/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_qnet.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../database/curiosity/compcogsci//nodeQs.txt_qnet.p'"
     ]
    }
   ],
   "source": [
    "[nodedf,edgedf,allngrps] = pickle.load(open('../database/curiosity/compcogsci/'+fname[fname.rfind('/'):]+'_qnet.p','rb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next step: use \"pickle to networkx\" notebook to do the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpg(nodedf,edgedf,level=1):\n",
    "    newndf = nodedf.loc[nodedf['level']<=level]\n",
    "    newedf = []\n",
    "    for row in edgedf.itertuples():\n",
    "        \n",
    "        if (nodedf.loc[nodedf['id']==row.start]['level'].values[0])<=(level-1):\n",
    "            newedf.append(row)\n",
    "    newedf = pd.DataFrame(newedf)\n",
    "    return newndf,newedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nodedf_l3,edgedf_l3] = simpg(nodedf,edgedf,level=3)\n",
    "[nodedf_l2,edgedf_l2] = simpg(nodedf,edgedf,level=2)\n",
    "\n",
    "pickle.dump([nodedf_l2,edgedf_l2,nodedf_l3,edgedf_l3,allngrps],open('../database/curiosity/compcogsci/Rich2019_the_qnet_simp.p','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
