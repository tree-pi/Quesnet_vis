{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantxt(fname):\n",
    "    rawname = fname+'_raw'\n",
    "    if fname[-3:]=='txt':\n",
    "        rawname = fname[:-4]+'_raw.txt'\n",
    "    \n",
    "    with open(fname, 'r') as f, open(rawname, 'a') as rawf:\n",
    "        content = f.readlines()\n",
    "        for line in f:\n",
    "            rawf.write(line)\n",
    "            \n",
    "    # remove whitespace at the end. keep the tab \\t to mark level of question    \n",
    "    content = [x.strip('\\n') for x in content] \n",
    "   \n",
    "    for line in content:\n",
    "        if line[0]==' ': # transform white spaces into tab which is used to count levels\n",
    "            line = line.replace('  ','\\t') \n",
    "        if line.find('？')>0: # deal with chinese characters\n",
    "            line = line.replace('？','?')\n",
    "        if line.find('。')>0:\n",
    "            line = line.replace('。','.')\n",
    "        with open(fname, 'w') as wf: # rewrite the original text name so nothing weird in the processed textfile.\n",
    "            wf.write(line+'\\n')\n",
    "    return content,cleanname\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to quesnet\n",
    "For paper notes, the first line will be the title of this paper, which should be linked to the paper data structure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getedge(head):\n",
    "    # get edge\n",
    "    if head.find('...')>0 and head.find('_')>0: # edge of a group head\n",
    "        ed = head[head.find('_')+1:head.find('...')]\n",
    "    else: # edge of single node\n",
    "        ed = head[head.find('_')+1:head.rfind('_')]\n",
    "    #unify the edge label names\n",
    "    if ed == 'a' or ed.lower()=='answer':\n",
    "        ed = 'answer' # rename the txt shorthand\n",
    "    elif ed == 'specify':\n",
    "        ed = 'specification'\n",
    "    # get speaker\n",
    "    if head.find('@')>0: # speaker other than this paper -- usually me\n",
    "        speaker = head[head.find('@')+1:]\n",
    "    else:\n",
    "        speaker = ''\n",
    "    return ed,speaker\n",
    "def node2label(node):\n",
    "    if node.find('\"')>0:\n",
    "        label = node[:node.find('\"')]\n",
    "        content = node[node.find('\"'):]\n",
    "    else:\n",
    "        label = node\n",
    "        content=\"\"\n",
    "    return label,content\n",
    "\n",
    "def txt2quesnet(outdir,combrepQ = True,fin='',nodedist={},alledge=[]):\n",
    "    for key in ['label','type','id','content','speaker','level']:\n",
    "        nodedist[key]=[]\n",
    "    with open(fin,'r') as f:\n",
    "        content = f.readlines()\n",
    "    \n",
    "    # create a paper entity\n",
    "    thisp = {'id':'Ep%d'%np.random.randint(100000)} #E=entity,p=paper\n",
    "    #FUTURE: may use other ways to record the paper info\n",
    "    fname = fin[fin.rfind('/')+1:] # get rid of the file directory \n",
    "    print(fname)\n",
    "    thisp['label']=fname.strip('.txt')\n",
    "    for ks,s in enumerate(fname):\n",
    "        if s.isdigit():\n",
    "            thisp['author'] = fname[:ks]\n",
    "            break\n",
    "    thisp['year']=fname[ks:ks+4]\n",
    "    # if the first line is the paper name\n",
    "    lstart=0 # which line to start reading\n",
    "    if content[0][0]=='#':\n",
    "        thisp['title']=content[0][4:].rstrip()\n",
    "        lstart=1\n",
    "    else:\n",
    "        print('paper title not provided')\n",
    "\n",
    "    \n",
    "    # create multiple question threads from each root\n",
    "    maxlevel = 20 # maximum 20 levels down the tree\n",
    "    allngrps=[]\n",
    "    for line in content[lstart:]:\n",
    "        \n",
    "        if len(line.strip())<1: # skip empty lines\n",
    "            continue\n",
    "        elif line[:2]=='##':#ending sign\n",
    "            break\n",
    "        else: # a valid new line\n",
    "            line = line.rstrip()\n",
    "            # new...\n",
    "            if line[0].isalpha(): # a root node doesn't start with tab\n",
    "                    rootlv=0\n",
    "                    rootlist = [[] for k in range(maxlevel)]# restart a new root list\n",
    "                    node = line\n",
    "                    edge = ''\n",
    "                    spkr = ''\n",
    "                    head = ''\n",
    "            else:\n",
    "                head = line.split(' ')[0]\n",
    "                if len(line.split(' '))==1: #either answer group head or end\n",
    "                    if line[-3:]=='...': #group head\n",
    "                        nodegrp = [] # for reading parallel nodes\n",
    "                        hdedge,hdspkr = getedge(head)\n",
    "                        continue\n",
    "                    elif line.find('end_')>0:\n",
    "                        allngrps.append(nodegrp)\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(line)\n",
    "                        print(\"can't recognize your grammar...\")  \n",
    "                        continue\n",
    "                else: #all other normal nodes\n",
    "                    node = \" \".join(line.split(' ')[1:])\n",
    "                    if head.find('...')<0: # a normal edge; otherwise a member of edge group, edge is given\n",
    "                        edge,spkr = getedge(head)\n",
    "                    else:\n",
    "                        edge,spkr = hdedge,hdspkr #inherent\n",
    "\n",
    "        # Construct the node dictionary, get nid   \n",
    "        level = int((len(line) - len(line.strip('\\t')))/len('\\t')) # an absolute level\n",
    "        label,content=node2label(node)\n",
    "        \n",
    "        if combrepQ and label in nodedist['label']:\n",
    "            nid = nodedist['id'][nodedist['label'].index(label)]\n",
    "        else:\n",
    "            if edge == 'answer':\n",
    "                nodedist['type'].append('Answer') \n",
    "                nid = 'a%d'%np.random.randint(100000)\n",
    "            elif  edge =='hypothesis':\n",
    "                nodedist['type'].append('hypothesis') \n",
    "                nid = 'ah%d'%np.random.randint(100000)\n",
    "            else:\n",
    "                nid = 'q%d'%np.random.randint(100000)\n",
    "                if level>0:\n",
    "                    nodedist['type'].append('Question')    \n",
    "                else:\n",
    "                    nodedist['type'].append('Root question')\n",
    "            nodedist['label'].append(label)\n",
    "            nodedist['id'].append(nid)\n",
    "            nodedist['content'].append(content)\n",
    "            nodedist['level'].append(level)\n",
    "            #nodedist['reference'].append(reference)\n",
    "            if len(spkr)==0:\n",
    "                spkr = thisp['id'] # if not specified, default speaker is this paper\n",
    "            nodedist['speaker'].append(spkr)\n",
    "        \n",
    "        if head.find('...')>0:\n",
    "            nodegrp.append(nid)       \n",
    "\n",
    "        \n",
    "        # Construct the edge dictionary    \n",
    "        rootlist[level]=nid             \n",
    "        if level>0:\n",
    "            if len(rootlist[level-1])==0:\n",
    "                print(node)\n",
    "                set_trace()\n",
    "            edgedict = {'start':rootlist[level-1],'end':nid,'label':edge,'id':'l%d'%np.random.randint(100000)}\n",
    "            if rootlist[level-1] == nid:\n",
    "                print(level)\n",
    "                print(line)\n",
    "                set_trace()\n",
    "            alledge.append(edgedict)   \n",
    "\n",
    "            \n",
    "    nodedf = pd.DataFrame(nodedist)\n",
    "    edgedf = pd.DataFrame(alledge) \n",
    "    #os.makedirs(filedir)\n",
    " \n",
    "    pickle.dump([nodedf,edgedf,allngrps,thisp],open(outdir+thisp['label']+'_qnet.p','bw'))\n",
    "    print('generated database in:\\n'+outdir+thisp['label']+'_qnet.p')\n",
    "    return thisp # output the paper entity. TODO: other entities mentioned in the nodes should also be added, so that return a full database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir='../database/curiosity/devpsych/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stahl2015_observing.txt\n",
      "generated database in:\n",
      "../database/curiosity/devpsych/Stahl2015_observing_qnet.p\n"
     ]
    }
   ],
   "source": [
    "fname='../txtnotes/papernotes/Stahl2015_observing.txt'\n",
    "Epaper=txt2quesnet(outdir,False,fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Ep63386',\n",
       " 'label': 'Stahl2015_observing',\n",
       " 'author': 'Stahl',\n",
       " 'year': '2015',\n",
       " 'title': 'Observing the unexpected enhances infants’ learning and exploration'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Epaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next step: use \"pickle to networkx\" notebook to do the visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Q net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQid(qtext,Qdic):\n",
    "    qtext = str(qtext)\n",
    "    if qtext in Qdic['label']:\n",
    "        idx = Qdic['label'].index(qtext)\n",
    "        if paper not in Qdic['paper'][idx]:\n",
    "            Qdic['paper'][idx].append(paper)\n",
    "        return Qdic['id'][idx]\n",
    "    else:\n",
    "        newid = 'Q%d'%np.random.randint(100000)\n",
    "        Qdic['id'].append(newid)\n",
    "        Qdic['label'].append(qtext)\n",
    "        Qdic['paper'].append([paper])\n",
    "        return newid\n",
    "def addedge(qids,etext,Edgedic):\n",
    "    if qids in Edgedic['startNend']:\n",
    "        idx = Edgedic['startNend'].index(qids)\n",
    "        if paper not in Edgedic['paper'][idx]:\n",
    "            Edgedic['paper'][idx].append(paper)\n",
    "        if etext not in Edgedic['label'][idx]:\n",
    "            Edgedic['label'][idx].append(etext)\n",
    "    else:\n",
    "        Edgedic['startNend'].append(qids)\n",
    "        Edgedic['id'].append('E%d'%np.random.randint(100000))\n",
    "        Edgedic['label'].append([etext])\n",
    "        Edgedic['paper'].append([paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir='../database/curiosity/devpsych/'\n",
    "# ignore both the answer and hypothesis\n",
    "pnames = ['Bonawitz2011-the','Stahl2015_observing']\n",
    "pname=pnames[1]\n",
    "[nodedf,edgedf,allngrps,thisp] = pickle.load(open(outdir+pname+'_qnet.p','rb'))\n",
    "Qedgs =[]\n",
    "\n",
    "for row in edgedf.itertuples(index=False):\n",
    "    if row.end[0]=='q':\n",
    "        thisid = row.end\n",
    "        if (row.start[0]=='a'): # a to q\n",
    "            prevqid = edgedf['start'].loc[edgedf['end']==row.start].values[0]\n",
    "            eid = 'l%d'%np.random.randint(100000)\n",
    "            if prevqid[0]!='q':\n",
    "                print('strange! Answer not following a question!')\n",
    "                set_trace()\n",
    "                continue\n",
    "        else:\n",
    "            prevqid = row.start\n",
    "            eid = row.id\n",
    "        elb = row.label\n",
    "\n",
    "        edgedict = {'start':prevqid,'end':thisid,'label':elb,'id':eid}\n",
    "        Qedgs.append(edgedict)\n",
    "Qnodes = []\n",
    "for node in nodedf.itertuples(index=False):\n",
    "    if node.id[0]=='q':\n",
    "        Qnodes.append(node)\n",
    "Qndf = pd.DataFrame(Qnodes)\n",
    "Qedf = pd.DataFrame(Qedgs)\n",
    "pickle.dump([Qndf,Qedf],open(outdir+pname+'_Qonly.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8900a2fa18d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../database/curiosity/devpsych/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mnodedf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgedf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallngrps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_qnet.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mQedgs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medgedf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pname' is not defined"
     ]
    }
   ],
   "source": [
    "# only ignore the answer but not the hypothesis\n",
    "[nodedf,edgedf,allngrps,thisp] = pickle.load(open(outdir+pname+'_qnet.p','rb'))\n",
    "Qedgs =[]\n",
    "\n",
    "for row in edgedf.itertuples(index=False):\n",
    "    if row.end[0]=='q' or row.end[:2]=='ah':\n",
    "        thisid = row.end\n",
    "        if (row.start[0]=='a' and row.start[1]!='h'): # a to q\n",
    "            prevqid = edgedf['start'].loc[edgedf['end']==row.start].values[0]\n",
    "            eid = 'l%d'%np.random.randint(100000)\n",
    "            if prevqid[0]!='q':\n",
    "                print('strange! Answer not following a question!')\n",
    "                set_trace()\n",
    "                continue\n",
    "        else:\n",
    "            prevqid = row.start\n",
    "            eid = row.id\n",
    "        elb = row.label\n",
    "\n",
    "        edgedict = {'start':prevqid,'end':thisid,'label':elb,'id':eid}\n",
    "        Qedgs.append(edgedict)\n",
    "Qnodes = []\n",
    "for node in nodedf.itertuples(index=False):\n",
    "    if node.id[0]=='q' or row.end[:2]=='ah':\n",
    "        Qnodes.append(node)\n",
    "Qndf = pd.DataFrame(Qnodes)\n",
    "Qedf = pd.DataFrame(Qedgs)\n",
    "pickle.dump([Qndf,Qedf],open(outdir+pname+'_Qonly.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpg(nodedf,edgedf,level=1):\n",
    "    newndf = nodedf.loc[nodedf['level']<=level]\n",
    "    newedf = []\n",
    "    for row in edgedf.itertuples():\n",
    "        \n",
    "        if (nodedf.loc[nodedf['id']==row.start]['level'].values[0])<=(level-1):\n",
    "            newedf.append(row)\n",
    "    newedf = pd.DataFrame(newedf)\n",
    "    return newndf,newedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nodedf_l3,edgedf_l3] = simpg(nodedf,edgedf,level=4)\n",
    "\n",
    "pickle.dump([nodedf_l3,edgedf_l3,allngrps],open(outdir+pname+'_lv4.p','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
