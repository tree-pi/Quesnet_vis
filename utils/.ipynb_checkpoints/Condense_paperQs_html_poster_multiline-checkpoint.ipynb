{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condense paper html generation \n",
    "\n",
    "# The program aims to generate the html file from the \n",
    "# condensed topic graph\n",
    "\n",
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = []\\ndata = {\"nodes\":ht_nodes,\"edges\":ht_edges}\\nwith open(\\'jscode/poster/json/fullQs_qnet1.json\\', \\'w\\') as outfile:  \\n    json.dump(data, outfile)\\n# save the complete html version\\nwith open(fdir+fin[:fin.rfind(\\'.p\\')]+\\'_node.txt\\', \\'w\\') as outfile:  \\n    json.dump(ht_nodes, outfile)\\nwith open(fdir+fin[:fin.rfind(\\'.p\\')]+\\'_edge.txt\\', \\'w\\') as outfile:  \\n    json.dump(ht_edges, outfile)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = '../database/curiosity/devpsych/Bonawitz2011-the_qnet.p' # designed for the poster \n",
    "fdir = fpath[:fpath.rfind('/')+1]\n",
    "fin = fpath[fpath.rfind('/')+1:]\n",
    "\n",
    "pagetitle = fin[:fin.rfind('_qnet')] # or could define anything else. will be shown on top of the %page\n",
    "\n",
    "pickfile=open(fdir+fin,'rb')\n",
    "mydict = pickle.load(pickfile)\n",
    "pickfile.close()\n",
    "\n",
    "# divde the node and link \n",
    "try:\n",
    "    [dic_node, dic_link, ansgrp,thispaper] = mydict\n",
    "    htmltitle = thispaper['title']\n",
    "    pageinfo = '%s et al. %s (Coder: Z.Li)'%(thispaper['author'],thispaper['year'])\n",
    "\n",
    "except:\n",
    "    [dic_node, dic_link] = mydict\n",
    "\n",
    "# graph initialization \n",
    "topic_graph = nx.Graph()\n",
    "# html json initialization\n",
    "ht_nodes = []\n",
    "ht_edges = []\n",
    "\n",
    "\n",
    "# add nodes into the graph\n",
    "(row, col) = dic_node.shape\n",
    "\n",
    "def wrap_by_word(s, n):\n",
    "    # returns a string where \\\\n is inserted between every n words\n",
    "    a = s.split()\n",
    "    ret = ''\n",
    "    for i in range(0, len(a), n):\n",
    "        ret += ' '.join(a[i:i+n]) + '\\n'\n",
    "    return ret\n",
    "\n",
    "\n",
    "for index in range(row):\n",
    "    nd_id = dic_node.iloc[index]['id']\n",
    "    nd_label = dic_node.iloc[index]['label']\n",
    "    nd_type = dic_node.iloc[index]['type']\n",
    "    nd_content = dic_node.iloc[index]['content']\n",
    "    nd_speaker = dic_node.iloc[index]['speaker']\n",
    "    \n",
    "    if nd_type == 'Answer':\n",
    "        nd_color = 'blue'\n",
    "        nd_size = 6\n",
    "    elif nd_type == 'Question':\n",
    "        nd_color = 'dodgerblue'\n",
    "        nd_size = 8\n",
    "    else:\n",
    "        nd_color = 'tomato'\n",
    "        nd_size = 10\n",
    "    \n",
    "    nd_label1 = wrap_by_word(nd_label,4)\n",
    "    if nd_type == 'Root question':\n",
    "        nd_label1 = wrap_by_word(nd_label,6)\n",
    "    if len(nd_label)>50 and nd_type != 'Root question':\n",
    "        fulllb = nd_label\n",
    "        nd_label1 = nd_label1[:50]+'...'\n",
    "        \n",
    "    ht_nodes.append({'id':nd_id, 'label': nd_label1,'fulllabel':nd_label, 'type':nd_type,\n",
    "                     'color': nd_color, 'size':nd_size, 'font':{'vadjust':'15'},\n",
    "                     'speaker':nd_speaker, 'content':nd_content})\n",
    "\n",
    "# add link into the graph \n",
    "(row, col) = dic_link.shape\n",
    "\n",
    "for index in range(row):\n",
    "    lk_id = dic_link.iloc[index]['id']\n",
    "    lk_from = dic_link.iloc[index]['start']\n",
    "    lk_to = dic_link.iloc[index]['end']\n",
    "    lk_label = dic_link.iloc[index]['label']\n",
    "    \n",
    "    ht_edges.append({'from':lk_from, 'to': lk_to, 'label': lk_label, 'color':{'inherit':'to'},\n",
    "                     'font':{'align':'middle'},'arrows':'to','length':5})\n",
    "\n",
    "    \n",
    "# output the html by revising the template    \n",
    "tfile = 'format/html_templates/html_website.html'\n",
    "rawname = fdir+fin[:fin.rfind('.p')]+'.html'\n",
    "with open(tfile, 'r') as f,open(rawname, 'w') as rawf:\n",
    "        content = f.readlines()\n",
    "        for kl,line in enumerate(content):            \n",
    "            if kl==5:\n",
    "                rawf.write('<TITLE>'+pagetitle+'</TITLE>')\n",
    "            elif kl==47:\n",
    "                rawf.write(htmltitle)\n",
    "            elif kl==50:\n",
    "                rawf.write(pageinfo)\n",
    "            elif kl==75:\n",
    "                rawf.write('var nodes = new vis.DataSet('+str(ht_nodes)+')\\n')\n",
    "            elif kl==77:\n",
    "                rawf.write('var edges = new vis.DataSet('+str(ht_edges)+')\\n')\n",
    "            else:\n",
    "                rawf.write(line)\n",
    "                \n",
    "# save the json import version \n",
    "\"\"\"data = []\n",
    "data = {\"nodes\":ht_nodes,\"edges\":ht_edges}\n",
    "with open('jscode/poster/json/fullQs_qnet1.json', 'w') as outfile:  \n",
    "    json.dump(data, outfile)\n",
    "# save the complete html version\n",
    "with open(fdir+fin[:fin.rfind('.p')]+'_node.txt', 'w') as outfile:  \n",
    "    json.dump(ht_nodes, outfile)\n",
    "with open(fdir+fin[:fin.rfind('.p')]+'_edge.txt', 'w') as outfile:  \n",
    "    json.dump(ht_edges, outfile)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../database/curiosity/devpsych/Stahl2015_observing_qnet.html'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawname"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
