[{"color": "tomato", "font": {"vadjust": "15"}, "label": "How to the exploration-exploitation dilemma?", "id": "q83949", "size": 10, "type": "Root question", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What are the\npossible solutions?\n", "id": "q94753", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "random exploration.\n", "id": "a69524", "size": 6, "type": "Answer", "content": "\"a decision-maker who learns to maximize a numerical reward signal1 may nevertheless make choices associated with lower reward value (exploration) due to a noisy response-generation process\"", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What is the\nalgorithm?\n", "id": "q42095", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "Standard RL with\ndelta learning rule.\n", "id": "a95721", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What is the\npolicy?\n", "id": "q79296", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "softmax choice function.\n", "id": "a26415", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "directed exploration. i.e.\nuncertainty-driven exploration.\n", "id": "a12314", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What is the\nalgorithm?\n", "id": "q11025", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "Knowledge RT(kRL). All\nthe same with\nsRL except adding\ninformation into reward.\n", "id": "a40938", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What is the\nreward?\n", "id": "q7774", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "Negative reward for\nthe given choice.\n", "id": "a34284", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What will the\nmodel be when\nthe information is\nnonlinear to the\nnumber of choosing?\n", "id": "q79733", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "the gamma kRL\nor gkRL model\nwith an exponential\nparameter on the\naccumulated information (total\nnumber of choosing).\n", "id": "a97244", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "Which model better\nexplains human behavior?\n", "id": "q72783", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "Not only the\nreward but also\ninformation should be\nconsidered to direct\nexploration.\n", "id": "a6134", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What is the\ntask?\n", "id": "q21370", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "Similar to Wilson\net al. but\nwith three options.\n", "id": "a43811", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What are the\nphases?\n", "id": "q85701", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "Forced choice (computer\nexposure of decks)\ntasks followed by\nfree choices.\n", "id": "a45848", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What are the\nconditions?\n", "id": "q56599", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "In the forced\nchoice phase, the\nexposure of different\ndecks can be\nunequal or equal.\n", "id": "a85674", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What is the\nresult?\n", "id": "q5467", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "How to evaluate?\n", "id": "q44418", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What are the\nqualitative evaluation?\n", "id": "q34496", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "In the first\ntrial after the\nforced choice phase,\nprobability of explore\nthe never informed\noption versus exploit\nthe most rewarded\noption, given the\nrewards are the\nsame.\n", "id": "a57828", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "dodgerblue", "font": {"vadjust": "15"}, "label": "What are the\nquantitative evaluation?\n", "id": "q10134", "size": 8, "type": "Question", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "BIC model comparison\nfor trial-by-trial data.\n", "id": "a8159", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "The proportion of\nchoosing exploration is\nmuch higher than\nexploitation or random\nwhich supports the\nkRL.\n", "id": "a71408", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}, {"color": "blue", "font": {"vadjust": "15"}, "label": "The BIC of\nkRL is lower\nthan sRL indicating\nbetter fit, yet\ngkRL is even\nbetter when considering\nall free trials.\n", "id": "a27940", "size": 6, "type": "Answer", "content": "", "speaker": "Ep9231"}]