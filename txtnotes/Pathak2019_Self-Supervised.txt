#[E]Self-Supervised Exploration via Disagreement
What is the algorithm?
	_answer_ Decide where to sample based on the model's state aka prioritize exploration when the variance between model emsemble predictions is big (not using model confidence itself bc deep NNs usually overfit). 
	_compare_ How is the algorithm different from other similar self-supervising algorithms?
		_specify_ What are the improvements on previous algorithm?
			_answers...
			... More stable in a stochastic world with high dimensional noises generated by agent's actions,  compared to #[P]Chuaet2018-Deep, #[P]Houthfoot2016-Variational and #[P]Pathak2017_Curiosity-driven. "If the source is ultimately unpredictable like a TV changes its channel randomly whenever the controller is touched upon, then it should induce infinite attraction to an error-driven learner."
			... More sample-efficient in a world with high-variance feedback, compared to prediction error based algorithms, compared to #[P]Oudeyer2009_what.
What is the task?
	_generalization_ Can this algorithm generalize to other tasks?
How good is the performance?
	_how to evaluate?